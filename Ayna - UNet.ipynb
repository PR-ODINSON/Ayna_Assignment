{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f9ea20",
   "metadata": {},
   "source": [
    "# Ayna ML Assignment – Polygon Colorization with UNet\n",
    "**Author:** Prithviraj Verma  \n",
    "**Task:** Train a UNet model to generate an RGB image of a colored polygon given a grayscale polygon image and a color name.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeaa20e",
   "metadata": {},
   "source": [
    "# Install & Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q wandb\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10189bf0",
   "metadata": {},
   "source": [
    "# Color Map + Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_MAP = {\n",
    "    \"red\": [1, 0, 0],\n",
    "    \"green\": [0, 1, 0],\n",
    "    \"blue\": [0, 0, 1],\n",
    "    \"yellow\": [1, 1, 0],\n",
    "    \"cyan\": [0, 1, 1],\n",
    "    \"magenta\": [1, 0, 1],\n",
    "    \"white\": [1, 1, 1],\n",
    "    \"black\": [0, 0, 0],\n",
    "    \"purple\": [0.5, 0, 0.5],\n",
    "    \"orange\": [1, 0.5, 0]\n",
    "}\n",
    "\n",
    "class PolygonColorDataset(Dataset):\n",
    "    def __init__(self, json_path, input_dir, output_dir, transform=None):\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "\n",
    "        for i, entry in enumerate(self.data):\n",
    "            missing = [k for k in ('input_polygon', 'output_image', 'colour') if k not in entry]\n",
    "            if missing:\n",
    "                raise KeyError(f\"Missing keys in entry {i}: {missing} — entry: {entry}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        in_path = os.path.join(self.input_dir, entry['input_polygon'])\n",
    "        out_path = os.path.join(self.output_dir, entry['output_image'])\n",
    "\n",
    "        input_img = Image.open(in_path).convert('L')\n",
    "        target_img = Image.open(out_path).convert('RGB')\n",
    "\n",
    "        input_tensor = self.transform(input_img)\n",
    "        target_tensor = self.transform(target_img)\n",
    "\n",
    "        color = COLOR_MAP.get(entry['colour'].lower())\n",
    "        if color is None:\n",
    "            raise ValueError(f\"Unknown color '{entry['colour']}' in entry: {entry}\")\n",
    "        color_tensor = torch.tensor(color, dtype=torch.float32).view(3, 1, 1).expand(3, *input_tensor.shape[1:])\n",
    "        model_input = torch.cat([input_tensor, color_tensor], dim=0)\n",
    "\n",
    "        return model_input, target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce1bd8",
   "metadata": {},
   "source": [
    "# DataLoader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PolygonColorDataset(\n",
    "    json_path='D:/Anya_data/dataset/training/data.json',\n",
    "    input_dir='D:/Anya_data/dataset/training/inputs',\n",
    "    output_dir='D:/Anya_data/dataset/training/outputs'\n",
    ")\n",
    "\n",
    "val_dataset = PolygonColorDataset(\n",
    "    json_path='D:/Anya_data/dataset/validation/data.json',\n",
    "    input_dir='D:/Anya_data/dataset/validation/inputs',\n",
    "    output_dir='D:/Anya_data/dataset/validation/outputs'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebced3",
   "metadata": {},
   "source": [
    "# UNet Model with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=3):\n",
    "        super().__init__()\n",
    "        self.enc1 = DoubleConv(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(128, 64)\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        b = self.bottleneck(self.pool3(e3))\n",
    "        d3 = self.dec3(torch.cat([self.up3(b), e3], 1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], 1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], 1))\n",
    "        return torch.sigmoid(self.final_conv(d1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2a1ac",
   "metadata": {},
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5995001",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet().to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22facc02",
   "metadata": {},
   "source": [
    "# Training and Validation Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(dataloader, desc=\"Training\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(dataloader, desc=\"Validation\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0556dcbd",
   "metadata": {},
   "source": [
    "# Start wandb + Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"ayna-polygon-color\", name=\"unet-final\")\n",
    "\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(model, train_loader)\n",
    "    val_loss = validate(model, val_loader)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
    "    wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd9873c",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(model, dataloader):\n",
    "    model.eval()\n",
    "    x, y = next(iter(dataloader))\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(x).cpu()\n",
    "    x = x.cpu()\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(10, 8))\n",
    "    for i in range(3):\n",
    "        axs[i][0].imshow(x[i, 0], cmap='gray')\n",
    "        axs[i][0].set_title(\"Polygon\")\n",
    "        axs[i][1].imshow(y[i].permute(1, 2, 0))\n",
    "        axs[i][1].set_title(\"Target\")\n",
    "        axs[i][2].imshow(preds[i].permute(1, 2, 0))\n",
    "        axs[i][2].set_title(\"Prediction\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call this after training\n",
    "# visualize(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df5e84",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize predictions on a few validation samples.\n",
    "    \n",
    "    Parameters:\n",
    "        model: Trained UNet model\n",
    "        dataloader: Validation DataLoader\n",
    "        num_samples: Number of samples to visualize\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    x_batch, y_batch = next(iter(dataloader))\n",
    "    x_batch = x_batch.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(x_batch).cpu()\n",
    "\n",
    "    x_batch = x_batch.cpu()\n",
    "    y_batch = y_batch.cpu()\n",
    "\n",
    "    # Plotting predictions\n",
    "    fig, axs = plt.subplots(num_samples, 3, figsize=(10, 4 * num_samples))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        axs[i][0].imshow(x_batch[i, 0], cmap='gray')\n",
    "        axs[i][0].set_title(\"Grayscale Polygon\", fontsize=12)\n",
    "        axs[i][0].axis('off')\n",
    "\n",
    "        axs[i][1].imshow(y_batch[i].permute(1, 2, 0))\n",
    "        axs[i][1].set_title(\"Ground Truth (Colored)\", fontsize=12)\n",
    "        axs[i][1].axis('off')\n",
    "\n",
    "        axs[i][2].imshow(preds[i].permute(1, 2, 0))\n",
    "        axs[i][2].set_title(\"Model Prediction\", fontsize=12)\n",
    "        axs[i][2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run inference on validation set\n",
    "test_model(model, val_loader, num_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb69fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
