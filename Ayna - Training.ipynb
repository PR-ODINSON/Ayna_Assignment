{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet-baseline</strong> at: <a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color/runs/kinoi8n0' target=\"_blank\">https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color/runs/kinoi8n0</a><br> View project at: <a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color' target=\"_blank\">https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250804_123101-kinoi8n0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Sakshi Sureka\\wandb\\run-20250804_123108-pbs0b3hj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color/runs/pbs0b3hj' target=\"_blank\">unet-baseline</a></strong> to <a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color' target=\"_blank\">https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color/runs/pbs0b3hj' target=\"_blank\">https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color/runs/pbs0b3hj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:09<00:00,  1.35s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3954, Val Loss=0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.3314, Val Loss=0.3615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.27s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.2943, Val Loss=0.3123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:09<00:00,  1.30s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.2576, Val Loss=0.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.2239, Val Loss=0.2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1898, Val Loss=0.1949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.1603, Val Loss=0.1789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.1339, Val Loss=0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.1217, Val Loss=0.1059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.1001, Val Loss=0.1178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:09<00:00,  1.31s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=0.0979, Val Loss=0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=0.0862, Val Loss=0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=0.0775, Val Loss=0.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=0.0671, Val Loss=0.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=0.0652, Val Loss=0.0482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=0.0596, Val Loss=0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=0.0584, Val Loss=0.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=0.0532, Val Loss=0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=0.0497, Val Loss=0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:08<00:00,  1.28s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=0.0533, Val Loss=0.0423\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Color map used for conditioning\n",
    "COLOR_MAP = {\n",
    "    \"red\": [1, 0, 0],\n",
    "    \"green\": [0, 1, 0],\n",
    "    \"blue\": [0, 0, 1],\n",
    "    \"yellow\": [1, 1, 0],\n",
    "    \"cyan\": [0, 1, 1],\n",
    "    \"magenta\": [1, 0, 1],\n",
    "    \"white\": [1, 1, 1],\n",
    "    \"black\": [0, 0, 0],\n",
    "    \"purple\": [0.5, 0, 0.5],\n",
    "    \"orange\": [1, 0.5, 0]# Added for your dataset\n",
    "}\n",
    "\n",
    "# Custom dataset\n",
    "class PolygonColorDataset(Dataset):\n",
    "    def __init__(self, json_path, input_dir, output_dir, transform=None):\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "\n",
    "        for i, entry in enumerate(self.data):\n",
    "            missing = [k for k in ('input_polygon', 'output_image', 'colour') if k not in entry]\n",
    "            if missing:\n",
    "                raise KeyError(f\"Missing keys in entry {i}: {missing} — entry: {entry}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        in_path = os.path.join(self.input_dir, entry['input_polygon'])\n",
    "        out_path = os.path.join(self.output_dir, entry['output_image'])\n",
    "\n",
    "        input_img = Image.open(in_path).convert('L')\n",
    "        target_img = Image.open(out_path).convert('RGB')\n",
    "\n",
    "        input_tensor = self.transform(input_img)  # (1, H, W)\n",
    "        target_tensor = self.transform(target_img)  # (3, H, W)\n",
    "\n",
    "        color = COLOR_MAP.get(entry['colour'].lower())\n",
    "        if color is None:\n",
    "            raise ValueError(f\"Unknown color '{entry['colour']}' in entry: {entry}\")\n",
    "        color_tensor = torch.tensor(color, dtype=torch.float32).view(3, 1, 1)\n",
    "        color_tensor = color_tensor.expand(3, *input_tensor.shape[1:])  # (3, H, W)\n",
    "\n",
    "        model_input = torch.cat([input_tensor, color_tensor], dim=0)  # (4, H, W)\n",
    "        return model_input, target_tensor\n",
    "\n",
    "# Dataset loaders\n",
    "train_dataset = PolygonColorDataset(\n",
    "    json_path='D:/Anya_data/dataset/training/data.json',\n",
    "    input_dir='D:/Anya_data/dataset/training/inputs',\n",
    "    output_dir='D:/Anya_data/dataset/training/outputs'\n",
    ")\n",
    "val_dataset = PolygonColorDataset(\n",
    "    json_path='D:/Anya_data/dataset/validation/data.json',\n",
    "    input_dir='D:/Anya_data/dataset/validation/inputs',\n",
    "    output_dir='D:/Anya_data/dataset/validation/outputs'\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# UNet model definition\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=3):\n",
    "        super().__init__()\n",
    "        self.enc1 = DoubleConv(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(128, 64)\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        b = self.bottleneck(self.pool3(e3))\n",
    "        d3 = self.dec3(torch.cat([self.up3(b), e3], 1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], 1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], 1))\n",
    "        return torch.sigmoid(self.final_conv(d1))\n",
    "\n",
    "# Training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet().to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training and validation loops\n",
    "def train_one_epoch(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(dataloader, desc=\"Training\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(dataloader, desc=\"Validation\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"ayna-polygon-color\", name=\"unet-baseline\")\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(model, train_loader)\n",
    "    val_loss = validate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
    "    wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "\n",
    "# Visualization\n",
    "def visualize(model, dataloader):\n",
    "    model.eval()\n",
    "    x, y = next(iter(dataloader))\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(x).cpu()\n",
    "    x = x.cpu()\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(10, 8))\n",
    "    for i in range(3):\n",
    "        axs[i][0].imshow(x[i, 0], cmap='gray')\n",
    "        axs[i][0].set_title(\"Polygon\")\n",
    "        axs[i][1].imshow(y[i].permute(1, 2, 0))\n",
    "        axs[i][1].set_title(\"Target\")\n",
    "        axs[i][2].imshow(preds[i].permute(1, 2, 0))\n",
    "        axs[i][2].set_title(\"Prediction\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Optional: visualize(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▇▆▅▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▆▃▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.05325</td></tr><tr><td>val_loss</td><td>0.04233</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet-baseline</strong> at: <a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color/runs/pbs0b3hj' target=\"_blank\">https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color/runs/pbs0b3hj</a><br> View project at: <a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color' target=\"_blank\">https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250804_123108-pbs0b3hj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Sakshi Sureka\\wandb\\run-20250804_124358-6szm5hp9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color/runs/6szm5hp9' target=\"_blank\">unet-augmented</a></strong> to <a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color' target=\"_blank\">https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color/runs/6szm5hp9' target=\"_blank\">https://wandb.ai/prithviraj-verma-iitram-institute-of-infrastructure-tech/ayna-polygon-color/runs/6szm5hp9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.83s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.4012, Val Loss=0.4527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.3465, Val Loss=0.5395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.3023, Val Loss=0.2989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.2760, Val Loss=0.2804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.2403, Val Loss=0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.2233, Val Loss=0.2058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.2060, Val Loss=0.2888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:11<00:00,  1.70s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.1778, Val Loss=0.3128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.1602, Val Loss=0.2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.1444, Val Loss=0.1757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=0.1357, Val Loss=0.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=0.1203, Val Loss=0.1118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=0.1195, Val Loss=0.1707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=0.1095, Val Loss=0.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=0.0995, Val Loss=0.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=0.0965, Val Loss=0.0830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=0.0920, Val Loss=0.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=0.0937, Val Loss=0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:11<00:00,  1.69s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=0.0830, Val Loss=0.0686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=0.0809, Val Loss=0.0905\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Color map\n",
    "COLOR_MAP = {\n",
    "    \"red\": [1, 0, 0],\n",
    "    \"green\": [0, 1, 0],\n",
    "    \"blue\": [0, 0, 1],\n",
    "    \"yellow\": [1, 1, 0],\n",
    "    \"cyan\": [0, 1, 1],\n",
    "    \"magenta\": [1, 0, 1],\n",
    "    \"white\": [1, 1, 1],\n",
    "    \"black\": [0, 0, 0],\n",
    "    \"purple\": [0.5, 0, 0.5],\n",
    "    \"orange\": [1, 0.5, 0]\n",
    "}\n",
    "\n",
    "# Custom dataset\n",
    "class PolygonColorDataset(Dataset):\n",
    "    def __init__(self, json_path, input_dir, output_dir, transform=None):\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "\n",
    "        for i, entry in enumerate(self.data):\n",
    "            missing = [k for k in ('input_polygon', 'output_image', 'colour') if k not in entry]\n",
    "            if missing:\n",
    "                raise KeyError(f\"Missing keys in entry {i}: {missing} — entry: {entry}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        in_path = os.path.join(self.input_dir, entry['input_polygon'])\n",
    "        out_path = os.path.join(self.output_dir, entry['output_image'])\n",
    "\n",
    "        input_img = Image.open(in_path).convert('L')\n",
    "        target_img = Image.open(out_path).convert('RGB')\n",
    "\n",
    "        input_tensor = self.transform(input_img)  # (1, H, W)\n",
    "        target_tensor = self.transform(target_img)  # (3, H, W)\n",
    "\n",
    "        color = COLOR_MAP.get(entry['colour'].lower())\n",
    "        if color is None:\n",
    "            raise ValueError(f\"Unknown color '{entry['colour']}' in entry: {entry}\")\n",
    "        color_tensor = torch.tensor(color, dtype=torch.float32).view(3, 1, 1)\n",
    "        color_tensor = color_tensor.expand(3, *input_tensor.shape[1:])\n",
    "\n",
    "        model_input = torch.cat([input_tensor, color_tensor], dim=0)\n",
    "        return model_input, target_tensor\n",
    "\n",
    "# Data transforms with augmentation\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Dataset loaders\n",
    "train_dataset = PolygonColorDataset(\n",
    "    json_path='D:/Anya_data/dataset/training/data.json',\n",
    "    input_dir='D:/Anya_data/dataset/training/inputs',\n",
    "    output_dir='D:/Anya_data/dataset/training/outputs'\n",
    ")\n",
    "val_dataset = PolygonColorDataset(\n",
    "    json_path='D:/Anya_data/dataset/validation/data.json',\n",
    "    input_dir='D:/Anya_data/dataset/validation/inputs',\n",
    "    output_dir='D:/Anya_data/dataset/validation/outputs'\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# UNet model with Dropout\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=3):\n",
    "        super().__init__()\n",
    "        self.enc1 = DoubleConv(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(128, 64)\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        b = self.bottleneck(self.pool3(e3))\n",
    "        d3 = self.dec3(torch.cat([self.up3(b), e3], 1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], 1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], 1))\n",
    "        return torch.sigmoid(self.final_conv(d1))\n",
    "\n",
    "# Training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet().to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# Training and validation loops\n",
    "def train_one_epoch(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(dataloader, desc=\"Training\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(dataloader, desc=\"Validation\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"ayna-polygon-color\", name=\"unet-augmented\")\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(model, train_loader)\n",
    "    val_loss = validate(model, val_loader)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
    "    wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "\n",
    "# Visualization\n",
    "def visualize(model, dataloader):\n",
    "    model.eval()\n",
    "    x, y = next(iter(dataloader))\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(x).cpu()\n",
    "    x = x.cpu()\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(10, 8))\n",
    "    for i in range(3):\n",
    "        axs[i][0].imshow(x[i, 0], cmap='gray')\n",
    "        axs[i][0].set_title(\"Polygon\")\n",
    "        axs[i][1].imshow(y[i].permute(1, 2, 0))\n",
    "        axs[i][1].set_title(\"Target\")\n",
    "        axs[i][2].imshow(preds[i].permute(1, 2, 0))\n",
    "        axs[i][2].set_title(\"Prediction\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# To use after training:\n",
    "# visualize(model, val_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7996825,
     "sourceId": 12653852,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
